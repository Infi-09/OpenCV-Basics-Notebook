{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b49c36",
   "metadata": {},
   "source": [
    "#                              OPENCV NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f9fe7",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e73b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libaries\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f44b4",
   "metadata": {},
   "source": [
    "##  Image Transformations\n",
    "   These are common techniques that you’ll likely apply to images, including translation, rotation, resizing, flipping, and cropping. We’ll explore each of these techniques in detail.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7593ac1",
   "metadata": {},
   "source": [
    "## Translation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04e11e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('images/dog.jpg')\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbbcd778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the translation matrix\n",
    "# Right or Left = (1, 0, tx) (R & D - positive)\n",
    "# Up or Down = (0, 1, ty)    (L & U - negative)\n",
    "M = np.float32([[1, 0, 30], [0, 1, 30]])\n",
    "# Shifting 30p right and 30p down \n",
    "shifted = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "cv2.imshow(\"Shifted Right and Down\", shifted)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "115912bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the translation matrix\n",
    "M = np.float32([[1, 0, -50], [0, 1, -50]])\n",
    "# Shifting 50p left and 50p up\n",
    "shifted = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "cv2.imshow(\"Shifted Right and Down\", shifted)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7c394",
   "metadata": {},
   "source": [
    "However, manually constructing this translation matrix and calling the cv2.warpAffine method takes a fair amount of code – and it’s not pretty code either! So, Creating functions are the best way to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96ffbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation(image, x, y):\n",
    "    \"\"\"\n",
    "    Gets the image , x and y as arguments and shift left or right with x and shift up or down with y \n",
    "    according to the values (positive or Negative)\n",
    "    x - positive (right)\n",
    "      -  negative (left)\n",
    "    y - positive (down)    \n",
    "      - negative (up)\n",
    "    \"\"\"\n",
    "    # Translation Matrix\n",
    "    M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "    shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb5283ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted = translation(img, 100, -100)\n",
    "cv2.imshow(\"Shifted Right and Up\", shifted)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afefa49",
   "metadata": {},
   "source": [
    "## Rotation\n",
    "Rotation is exactly what it sounds like: rotating an image by some angle q. In this section, we’ll explore how to rotate an image. We’ll use q to represent by how many degrees we are rotating the image. Later, I’ll provide another convenience method, rotate, to make performing rotations on\n",
    "images easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4c91e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('images\\dog.jpg')\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9315c154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h, w) = img.shape[:2]\n",
    "centre = (w//2, h//2)\n",
    "\n",
    "M = cv2.getRotationMatrix2D(centre, 50, 1.0)\n",
    "rotated = cv2.warpAffine(img, M, (w, h))\n",
    "cv2.imshow(\"Rotated 50 degree\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a81e2cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = cv2.getRotationMatrix2D(centre, -120, 1.0)\n",
    "rotated = cv2.warpAffine(img, M, (w, h))\n",
    "cv2.imshow(\"Rotated -120 degree\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24a6636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create functiion for rotation\n",
    "def rotation(image, angle, centre=None, scale=1.0):\n",
    "    (h, w) = image.shape[:2]\n",
    "    if centre is None:\n",
    "        (w, h) = (w//2, h//2)\n",
    "        \n",
    "    M = cv2.getRotationMatrix2D(centre, angle, scale)    \n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03e3eec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated = rotation(img, 15, scale=0.5)\n",
    "cv2.imshow(\"Rotated 75 degree\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f40058",
   "metadata": {},
   "source": [
    "## Resizing\n",
    "Resizing the image by defining the aspect ratio of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "846d3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the width\n",
    "w = 85 / img.shape[1]\n",
    "dim_width = (85, int(w * img.shape[0]))\n",
    "\n",
    "# Resize the height\n",
    "h = 85 / img.shape[0]\n",
    "dim_height = (85, int(h * img.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27d14a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the resize function in Cv2 (Width resizing)\n",
    "resized = cv2.resize(img, dim_width, interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow(\"resized\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2866839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the resize function in Cv2 (Width resizing)\n",
    "resized = cv2.resize(img, dim_height, interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow(\"resized\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c319c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the function for resize\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    (h, w) = image.shape[:2]\n",
    "    dim = None\n",
    "    \n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    \n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(r * w), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(r * h))\n",
    "        \n",
    "    rotated = cv2.resize(image, dim, interpolation=inter)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86d88f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized = resize(img, height=90)\n",
    "cv2.imshow(\"Resized\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f74cd2",
   "metadata": {},
   "source": [
    "## Flipping\n",
    "Next up on our image transformations to explore is flipping an image. We can flip an image around either the x or y axis, or even both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36bd8f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vertical Flip\n",
    "flipped = cv2.flip(img, 0)\n",
    "cv2.imshow(\"Flipped Vertically\", flipped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e984850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Horizontal Flip\n",
    "flipped = cv2.flip(img, 1)\n",
    "cv2.imshow(\"Flipped Horizontally\", flipped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24a20e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both horizontal and the vertical flip\n",
    "flipped = cv2.flip(img, -1)\n",
    "cv2.imshow(\"Flipped Both Horizontally and Vertically\", flipped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1448ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "def flip(image, flip_code=None):\n",
    "    if flip_code is None:\n",
    "        return image\n",
    "    else:\n",
    "        flipped = cv2.flip(image, flip_code)\n",
    "        return flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b790555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped = flip(img, flip_code=-1)\n",
    "cv2.imshow(\"Flipped Both Horizontally and Vertically\", flipped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed85219",
   "metadata": {},
   "source": [
    "## Cropping\n",
    "When we crop an image, we want to remove the outer parts of the image that we are not interested in. We can accomplish image cropping by using NumPy array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5e43da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 333, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b7b09f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped = img[50:200, 100:300]\n",
    "cv2.imshow(\"Cropped\", cropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86fe6f",
   "metadata": {},
   "source": [
    "## Image Arithmetic\n",
    "We all know basic arithmetic operations like addition and subtraction. But when working with images,\n",
    "we need to keep in mind the limits of our color space and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb539071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add two uint8 using cv2: [[255]] \n",
      "Subtract two uint8 using cv2: [[0]] \n",
      "Add two uint8 using Normal operation: [44] \n",
      "Add two uint8 using Normal operation: [156] \n"
     ]
    }
   ],
   "source": [
    "x = np.uint8([200])\n",
    "y = np.uint8([100])\n",
    "\n",
    "# Cv2 functions\n",
    "print(\"Add two uint8 using cv2: {} \".format(cv2.add(x, y)))\n",
    "print(\"Subtract two uint8 using cv2: {} \".format(cv2.subtract(y, x)))\n",
    "\n",
    "# Normal operation\n",
    "print(\"Add two uint8 using Normal operation: {} \".format(x + y))\n",
    "print(\"Add two uint8 using Normal operation: {} \".format(y - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c87f8ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets add some cool np array to our imge dog (Adding)\n",
    "M = np.ones(img.shape, dtype=\"uint8\")*100\n",
    "added = cv2.add(img, M)\n",
    "cv2.imshow(\"Added\", added)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6e261f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets subtract some cool np array to our imge dog (Subtracting)\n",
    "M = np.ones(img.shape, dtype=\"uint8\")*100\n",
    "sub = cv2.subtract(img, M)\n",
    "cv2.imshow(\"Subtracted\", sub)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4128ce",
   "metadata": {},
   "source": [
    "## Bitwise Operations\n",
    "Now we will review four bitwise operations: AND, OR, XOR, and NOT. These four operations, while very basic and low level, are paramount to image processing, especially when we start working with masks in Section 4.4.  Bitwise operations operate in a binary manner and are represented as grayscale images. A given pixel is turned “off” if it has a value of zero, and it is turned “on” if the pixel has a value greater than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a2c95db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create two shape for using the bitwise operations\n",
    "# Rectangle\n",
    "canvas = np.zeros((300, 300), dtype='uint8')\n",
    "rectangle = cv2.rectangle(canvas, (25, 25), (275, 275), 255, -1)\n",
    "cv2.imshow(\"Rectangle\", rectangle)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e5d6ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Circle\n",
    "canvas = np.zeros((300, 300), dtype='uint8')\n",
    "circle = cv2.circle(canvas, (150, 150), 150, 255, -1)\n",
    "cv2.imshow(\"Circle\", circle)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d354a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bitwise Operations\n",
    "# AND\n",
    "bitwiseAnd = cv2.bitwise_and(rectangle, circle)\n",
    "cv2.imshow(\"AND\", bitwiseAnd)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7ca07fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "bitwiseOr = cv2.bitwise_or(rectangle, circle)\n",
    "cv2.imshow(\"OR\", bitwiseOr)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a3cf4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XOR\n",
    "bitwiseXor = cv2.bitwise_xor(rectangle, circle)\n",
    "cv2.imshow(\"OR\", bitwiseXor)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be3b085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOT\n",
    "bitwiseNot = cv2.bitwise_not(rectangle)\n",
    "cv2.imshow(\"NOT\", bitwiseNot)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b662934",
   "metadata": {},
   "source": [
    "## Masking\n",
    "In the previous section, we explored bitwise functions. Now we are ready to explore masking, an\n",
    "extremely powerful and useful technique in computer vision and image processing. Using a mask allows us to focus only on the portions of the image that interests us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48bf605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 600, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('images/dc.jpg')\n",
    "print(img.shape)\n",
    "cv2.imshow(\"DC\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a87b7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masking using Rectangle\n",
    "mask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "(cX, cY) = (img.shape[1]//2, img.shape[0]//2)\n",
    "cv2.rectangle(mask, (cX+250, cY-cY), (cX+140, cY-75), 255, -1)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28e1030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imshow(\"Masked\", masked)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d40118aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masking with circle\n",
    "mask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "(cX, cY) = (img.shape[1]//2, img.shape[0]//2)\n",
    "cv2.circle(mask, (cX-120, cY-20), 35, 255, -1)\n",
    "cv2.imshow(\"Masked with circle\", mask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae4325bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imshow(\"Masked\", masked)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28229d87",
   "metadata": {},
   "source": [
    "## Splitting and Merging channels\n",
    "A color image consists of multiple channels: a Red, a Green, and a Blue component. We have seen that we can access these components via indexing into NumPy arrays. But what if we wanted to split an image into its respective components? As you’ll see, we’ll make use of the cv2.split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4034c0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 68,  68,  67, ..., 101, 117, 132],\n",
      "       [ 68,  69,  67, ...,  99, 116, 130],\n",
      "       [ 68,  69,  68, ...,  98, 114, 128],\n",
      "       ...,\n",
      "       [  0,   5,  13, ...,   9,  10,  19],\n",
      "       [  7,  35,  40, ...,   0,   4,  15],\n",
      "       [ 15,  56,  60, ...,   0,   7,  21]], dtype=uint8), array([[ 67,  67,  66, ..., 105, 121, 136],\n",
      "       [ 67,  68,  66, ..., 103, 120, 134],\n",
      "       [ 67,  68,  67, ..., 102, 118, 132],\n",
      "       ...,\n",
      "       [  1,  10,  23, ...,  24,  26,  37],\n",
      "       [ 10,  40,  52, ...,  18,  22,  34],\n",
      "       [ 15,  61,  72, ...,  23,  29,  43]], dtype=uint8), array([[ 71,  71,  70, ...,  93, 109, 124],\n",
      "       [ 71,  72,  70, ...,  92, 109, 123],\n",
      "       [ 71,  72,  69, ...,  91, 107, 121],\n",
      "       ...,\n",
      "       [  5,  11,  23, ...,  33,  38,  48],\n",
      "       [ 14,  43,  52, ...,  23,  29,  41],\n",
      "       [ 21,  64,  74, ...,  25,  34,  48]], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "(B, G, R) = cv2.split(img)\n",
    "print((B, G, R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe057874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Blue\", B)\n",
    "cv2.imshow(\"Grenn\", G)\n",
    "cv2.imshow(\"Red\", R)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f207de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = cv2.merge([B, G, R])\n",
    "cv2.imshow(\"Merged BGR\", merged)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e538758e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\n",
    "cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\n",
    "cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1663c8",
   "metadata": {},
   "source": [
    "## Color Space\n",
    "The Hue-Saturation-Value (HSV) color space is more similar to how humans think and conceive of color. Then there is the L*a*b* color space, which is more tuned to how humans perceive color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1eabb7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RGB to gray scale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "\n",
    "# RGB to HSV color space\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"HSV\", hsv)\n",
    "\n",
    "# RGB to L*a*b\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "cv2.imshow(\"L*a*b\", lab)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
